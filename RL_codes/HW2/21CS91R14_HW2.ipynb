{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL HW2\n",
    "---\n",
    "## *Name*: Sunandan Adhikary                                         \n",
    "## Roll no: 21CS91R14    \n",
    "\n",
    "1. $\\epsilon$-greedy policy is implemented in the code. $\\epsilon$-greedy policy is used to select the next action. \n",
    "     ```\n",
    "     > Test1: ok\n",
    "     > Test2: ok\n",
    "     > Test3: ok\n",
    "     ```\n",
    " \n",
    "2. \n",
    "    - **a)** Completed `initialize_models()`, `get_q_values()`, `update_target()`, `calc_loss()`, `add_optimizer()` functions in \n",
    "\n",
    "        `q2_1_linear_torch.py`. After training the agent was able to achieve the maximum *~6.2 average reward* by training with the provided \n",
    "\n",
    "        parameters within *5.533073902130127 ~ 6.31389594078064 s*.\n",
    "\n",
    "        - sample training score vs epoch plot 1\n",
    "\n",
    "        ![sample training score plot 1](./linear_scores_5.533073902130127s.png)\n",
    "\n",
    "        <!-- <img src= \"./results/q2_1_linear/scores_5.745505094528198s.png\", width = \"400\"> -->\n",
    "\n",
    "        - sample training score vs epoch plot 2\n",
    "\n",
    "        ![sample training score plot 2](./linear_scores_5.745505094528198s.png)\n",
    "\n",
    "     -  **b)**  Completed `initialize_models()`, `get_q_values()` functions in `q2_2_nature_torch.py`. Prepared the CNN for the agent following the [mother paper](https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf). ![dqnn](./naturedqnn.png)\n",
    "\n",
    "        After training the agent was able to achieve the maximum *~6.2 average reward* by training with the provided parameters within *9.37676191329956 ~ 9.57876191329956s s*.\n",
    "\n",
    "        - sample training score vs epoch plot 1\n",
    "\n",
    "        ![sample training score plot 1](./nature_scores_9.37676191329956s.png)\n",
    "\n",
    "        - sample training score vs epoch plot 2\n",
    "\n",
    "        ![sample training score plot 2](./nature_scores_9.560451984405518s.png)\n",
    " \n",
    " \n",
    "3. Note that some extra lines of codes were added at the end of the three run files to measure the time. (tagged with `# new`) More sample score images are available in `./results/` with their\n",
    "\n",
    "training times.\n",
    "\n",
    "\n",
    "4. **To Infer: DQN implemented following the NIPS paper trains faster and reaches the maximum average reward .**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
